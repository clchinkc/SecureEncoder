[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "send_from_directory",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "session",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "secure_filename",
        "importPath": "werkzeug.utils",
        "description": "werkzeug.utils",
        "isExtraImport": true,
        "detail": "werkzeug.utils",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "werkzeug.exceptions",
        "description": "werkzeug.exceptions",
        "isExtraImport": true,
        "detail": "werkzeug.exceptions",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "Faker",
        "importPath": "faker",
        "description": "faker",
        "isExtraImport": true,
        "detail": "faker",
        "documentation": {}
    },
    {
        "label": "huffman_compress",
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "isExtraImport": true,
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "huffman_decompress",
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "isExtraImport": true,
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "zlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zlib",
        "description": "zlib",
        "detail": "zlib",
        "documentation": {}
    },
    {
        "label": "brotli",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "brotli",
        "description": "brotli",
        "detail": "brotli",
        "documentation": {}
    },
    {
        "label": "zstandard",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zstandard",
        "description": "zstandard",
        "detail": "zstandard",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "CORS",
        "importPath": "flask_cors",
        "description": "flask_cors",
        "isExtraImport": true,
        "detail": "flask_cors",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "RotatingFileHandler",
        "importPath": "logging.handlers",
        "description": "logging.handlers",
        "isExtraImport": true,
        "detail": "logging.handlers",
        "documentation": {}
    },
    {
        "label": "binascii",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "binascii",
        "description": "binascii",
        "detail": "binascii",
        "documentation": {}
    },
    {
        "label": "urllib.parse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "rsa",
        "importPath": "cryptography.hazmat.primitives.asymmetric",
        "description": "cryptography.hazmat.primitives.asymmetric",
        "isExtraImport": true,
        "detail": "cryptography.hazmat.primitives.asymmetric",
        "documentation": {}
    },
    {
        "label": "padding",
        "importPath": "cryptography.hazmat.primitives.asymmetric",
        "description": "cryptography.hazmat.primitives.asymmetric",
        "isExtraImport": true,
        "detail": "cryptography.hazmat.primitives.asymmetric",
        "documentation": {}
    },
    {
        "label": "hashes",
        "importPath": "cryptography.hazmat.primitives",
        "description": "cryptography.hazmat.primitives",
        "isExtraImport": true,
        "detail": "cryptography.hazmat.primitives",
        "documentation": {}
    },
    {
        "label": "serialization",
        "importPath": "cryptography.hazmat.primitives",
        "description": "cryptography.hazmat.primitives",
        "isExtraImport": true,
        "detail": "cryptography.hazmat.primitives",
        "documentation": {}
    },
    {
        "label": "AESGCM",
        "importPath": "cryptography.hazmat.primitives.ciphers.aead",
        "description": "cryptography.hazmat.primitives.ciphers.aead",
        "isExtraImport": true,
        "detail": "cryptography.hazmat.primitives.ciphers.aead",
        "documentation": {}
    },
    {
        "label": "default_backend",
        "importPath": "cryptography.hazmat.backends",
        "description": "cryptography.hazmat.backends",
        "isExtraImport": true,
        "detail": "cryptography.hazmat.backends",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "heapq",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "heapq",
        "description": "heapq",
        "detail": "heapq",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "SQLAlchemy",
        "importPath": "flask_sqlalchemy",
        "description": "flask_sqlalchemy",
        "isExtraImport": true,
        "detail": "flask_sqlalchemy",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "lz77_compress",
        "importPath": "src.compression_decompression",
        "description": "src.compression_decompression",
        "isExtraImport": true,
        "detail": "src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "lz77_decompress",
        "importPath": "src.compression_decompression",
        "description": "src.compression_decompression",
        "isExtraImport": true,
        "detail": "src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "lzw_compress",
        "importPath": "src.compression_decompression",
        "description": "src.compression_decompression",
        "isExtraImport": true,
        "detail": "src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "lzw_decompress",
        "importPath": "src.compression_decompression",
        "description": "src.compression_decompression",
        "isExtraImport": true,
        "detail": "src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "zstd_compress",
        "importPath": "src.compression_decompression",
        "description": "src.compression_decompression",
        "isExtraImport": true,
        "detail": "src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "zstd_decompress",
        "importPath": "src.compression_decompression",
        "description": "src.compression_decompression",
        "isExtraImport": true,
        "detail": "src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "deflate_compress",
        "importPath": "src.compression_decompression",
        "description": "src.compression_decompression",
        "isExtraImport": true,
        "detail": "src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "deflate_decompress",
        "importPath": "src.compression_decompression",
        "description": "src.compression_decompression",
        "isExtraImport": true,
        "detail": "src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "brotli_compress",
        "importPath": "src.compression_decompression",
        "description": "src.compression_decompression",
        "isExtraImport": true,
        "detail": "src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "brotli_decompress",
        "importPath": "src.compression_decompression",
        "description": "src.compression_decompression",
        "isExtraImport": true,
        "detail": "src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "encode_base64",
        "importPath": "src.encoder_decoder",
        "description": "src.encoder_decoder",
        "isExtraImport": true,
        "detail": "src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "decode_base64",
        "importPath": "src.encoder_decoder",
        "description": "src.encoder_decoder",
        "isExtraImport": true,
        "detail": "src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "encode_hex",
        "importPath": "src.encoder_decoder",
        "description": "src.encoder_decoder",
        "isExtraImport": true,
        "detail": "src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "decode_hex",
        "importPath": "src.encoder_decoder",
        "description": "src.encoder_decoder",
        "isExtraImport": true,
        "detail": "src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "encode_utf8",
        "importPath": "src.encoder_decoder",
        "description": "src.encoder_decoder",
        "isExtraImport": true,
        "detail": "src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "decode_utf8",
        "importPath": "src.encoder_decoder",
        "description": "src.encoder_decoder",
        "isExtraImport": true,
        "detail": "src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "encode_latin1",
        "importPath": "src.encoder_decoder",
        "description": "src.encoder_decoder",
        "isExtraImport": true,
        "detail": "src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "decode_latin1",
        "importPath": "src.encoder_decoder",
        "description": "src.encoder_decoder",
        "isExtraImport": true,
        "detail": "src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "encode_ascii",
        "importPath": "src.encoder_decoder",
        "description": "src.encoder_decoder",
        "isExtraImport": true,
        "detail": "src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "decode_ascii",
        "importPath": "src.encoder_decoder",
        "description": "src.encoder_decoder",
        "isExtraImport": true,
        "detail": "src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "encode_url",
        "importPath": "src.encoder_decoder",
        "description": "src.encoder_decoder",
        "isExtraImport": true,
        "detail": "src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "decode_url",
        "importPath": "src.encoder_decoder",
        "description": "src.encoder_decoder",
        "isExtraImport": true,
        "detail": "src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "ensure_aes_key",
        "importPath": "src.encryption_decryption",
        "description": "src.encryption_decryption",
        "isExtraImport": true,
        "detail": "src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "importPath": "src.encryption_decryption",
        "description": "src.encryption_decryption",
        "isExtraImport": true,
        "detail": "src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "importPath": "src.encryption_decryption",
        "description": "src.encryption_decryption",
        "isExtraImport": true,
        "detail": "src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "generate_rsa_keys",
        "importPath": "src.encryption_decryption",
        "description": "src.encryption_decryption",
        "isExtraImport": true,
        "detail": "src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "rsa_encrypt",
        "importPath": "src.encryption_decryption",
        "description": "src.encryption_decryption",
        "isExtraImport": true,
        "detail": "src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "rsa_decrypt",
        "importPath": "src.encryption_decryption",
        "description": "src.encryption_decryption",
        "isExtraImport": true,
        "detail": "src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "huffman_compress",
        "importPath": "src.huffman",
        "description": "src.huffman",
        "isExtraImport": true,
        "detail": "src.huffman",
        "documentation": {}
    },
    {
        "label": "huffman_decompress",
        "importPath": "src.huffman",
        "description": "src.huffman",
        "isExtraImport": true,
        "detail": "src.huffman",
        "documentation": {}
    },
    {
        "label": "db",
        "importPath": "src.md5_model",
        "description": "src.md5_model",
        "isExtraImport": true,
        "detail": "src.md5_model",
        "documentation": {}
    },
    {
        "label": "MD5Hash",
        "importPath": "src.md5_model",
        "description": "src.md5_model",
        "isExtraImport": true,
        "detail": "src.md5_model",
        "documentation": {}
    },
    {
        "label": "md5_encode",
        "importPath": "src.md5_model",
        "description": "src.md5_model",
        "isExtraImport": true,
        "detail": "src.md5_model",
        "documentation": {}
    },
    {
        "label": "md5_decode",
        "importPath": "src.md5_model",
        "description": "src.md5_model",
        "isExtraImport": true,
        "detail": "src.md5_model",
        "documentation": {}
    },
    {
        "label": "create_app",
        "importPath": "src.create_app",
        "description": "src.create_app",
        "isExtraImport": true,
        "detail": "src.create_app",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "src.app",
        "description": "src.app",
        "isExtraImport": true,
        "detail": "src.app",
        "documentation": {}
    },
    {
        "label": "stringify",
        "importPath": "flatted",
        "description": "flatted",
        "isExtraImport": true,
        "detail": "flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "flatted",
        "description": "flatted",
        "isExtraImport": true,
        "detail": "flatted",
        "documentation": {}
    },
    {
        "label": "FLASK_DEBUG",
        "kind": 5,
        "importPath": "SecureEncoderFlask.instance.config",
        "description": "SecureEncoderFlask.instance.config",
        "peekOfCode": "FLASK_DEBUG = True\nSECRET_KEY = os.urandom(24)\nFLASK_PORT = 5000",
        "detail": "SecureEncoderFlask.instance.config",
        "documentation": {}
    },
    {
        "label": "SECRET_KEY",
        "kind": 5,
        "importPath": "SecureEncoderFlask.instance.config",
        "description": "SecureEncoderFlask.instance.config",
        "peekOfCode": "SECRET_KEY = os.urandom(24)\nFLASK_PORT = 5000",
        "detail": "SecureEncoderFlask.instance.config",
        "documentation": {}
    },
    {
        "label": "FLASK_PORT",
        "kind": 5,
        "importPath": "SecureEncoderFlask.instance.config",
        "description": "SecureEncoderFlask.instance.config",
        "peekOfCode": "FLASK_PORT = 5000",
        "detail": "SecureEncoderFlask.instance.config",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "def index():\n    app.logger.debug('This is a debug message, visible only in development')\n    app.logger.warning('This warning is logged in production')\n    return \"Hello, please check your log configuration based on the environment.\"\ndef allowed_file(filename):\n    return '.' in filename and filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']\n@app.route('/api/upload_key', methods=['POST'])\ndef upload_key():\n    file = request.files['file']\n    if file.filename == '':",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "allowed_file",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "def allowed_file(filename):\n    return '.' in filename and filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']\n@app.route('/api/upload_key', methods=['POST'])\ndef upload_key():\n    file = request.files['file']\n    if file.filename == '':\n        app.logger.error(\"No file selected for upload\")\n        return jsonify({'error': 'No file selected'}), 400\n    if file and allowed_file(file.filename):\n        filename = secure_filename(file.filename)",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "upload_key",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "def upload_key():\n    file = request.files['file']\n    if file.filename == '':\n        app.logger.error(\"No file selected for upload\")\n        return jsonify({'error': 'No file selected'}), 400\n    if file and allowed_file(file.filename):\n        filename = secure_filename(file.filename)\n        file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n        return jsonify({'message': 'File uploaded successfully', 'filename': filename}), 201\n    app.logger.error(\"Invalid file type, a '.pem' file is needed\")",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "list_files",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "def list_files():\n    files = [f for f in os.listdir(app.config['UPLOAD_FOLDER']) if os.path.isfile(os.path.join(app.config['UPLOAD_FOLDER'], f))]\n    return jsonify(files), 200\n@app.route('/api/download_key/<filename>')\ndef download_key(filename):\n    file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n    if not os.path.exists(file_path):\n        app.logger.error(\"File not found\")\n        return jsonify({'error': 'Key not found'}), 404\n    return send_from_directory(app.config['UPLOAD_FOLDER'], filename, as_attachment=True)",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "download_key",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "def download_key(filename):\n    file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n    if not os.path.exists(file_path):\n        app.logger.error(\"File not found\")\n        return jsonify({'error': 'Key not found'}), 404\n    return send_from_directory(app.config['UPLOAD_FOLDER'], filename, as_attachment=True)\n@app.route('/api/delete_key/<filename>', methods=['DELETE'])\ndef delete_key(filename):\n    file_path = os.path.join(app.config['UPLOAD_FOLDER'], secure_filename(filename))\n    if os.path.exists(file_path):",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "delete_key",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "def delete_key(filename):\n    file_path = os.path.join(app.config['UPLOAD_FOLDER'], secure_filename(filename))\n    if os.path.exists(file_path):\n        os.remove(file_path)\n        return jsonify({'message': 'File deleted successfully'}), 204\n    else:\n        return jsonify({'error': 'File not found'}), 404\n@app.route('/api/save_text', methods=['PATCH'])\ndef save_text():\n    data = request.get_json()",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "save_text",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "def save_text():\n    data = request.get_json()\n    current_text = session.get('text', None)\n    new_text = data.get('new_text', None)\n    if current_text is None and new_text is None:\n        return jsonify({'message': 'No text provided'}), 400\n    elif current_text is None and new_text is not None:\n        session['text'] = new_text\n        return jsonify({'message': 'Text created successfully', 'text': new_text}), 201\n    elif current_text is not None and new_text is None:",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "process_text",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "def process_text():\n    data = request.get_json()\n    session['text'] = data['text']\n    session['operation'] = data['operation']\n    session['action'] = data['action']\n    operations = {\n        'encode': {\n            'base64': encode_base64,\n            'hex': encode_hex,\n            'utf8': encode_utf8,",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "apply_security_headers",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "def apply_security_headers(response):\n    response.headers['Strict-Transport-Security'] = 'max-age=63072000; includeSubDomains'\n    response.headers[\"Content-Security-Policy\"] = \"default-src 'self'; script-src 'self'; object-src 'none';\"\n    response.headers[\"X-Frame-Options\"] = \"SAMEORIGIN\"\n    response.headers[\"X-Content-Type-Options\"] = \"nosniff\"\n    response.headers[\"X-XSS-Protection\"] = \"1; mode=block\"\n    response.headers[\"Referrer-Policy\"] = \"no-referrer-when-downgrade\"\n    return response\n@app.after_request\ndef add_session_to_response(response):",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "add_session_to_response",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "def add_session_to_response(response):\n    response.set_cookie('files', json.dumps(session.get('files', [])))\n    response.set_cookie('result', session.get('result', ''))\n    response.set_cookie('operation', session.get('operation', ''))\n    response.set_cookie('action', session.get('action', ''))\n    response.set_cookie('text', session.get('text', ''))\n    return response\n@app.errorhandler(Exception)\ndef handle_exception(e):\n    if isinstance(e, HTTPException):",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "handle_exception",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "def handle_exception(e):\n    if isinstance(e, HTTPException):\n        return e\n    app.logger.error(f\"Unhandled exception: {str(e)}\")\n    return jsonify({'error': str(e)}), 500 if isinstance(e, KeyError) or isinstance(e, ValueError) else 400\ndef main():\n    app.run(host='0.0.0.0', port=int(app.config['FLASK_PORT']), debug=app.config['FLASK_DEBUG'], use_reloader=True, threaded=True)",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "def main():\n    app.run(host='0.0.0.0', port=int(app.config['FLASK_PORT']), debug=app.config['FLASK_DEBUG'], use_reloader=True, threaded=True)",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "SecureEncoderFlask.src.app",
        "description": "SecureEncoderFlask.src.app",
        "peekOfCode": "app = create_app()\nwith app.app_context():\n    db.create_all()\n    faker = Faker()\n    populate_db(faker, 10)\nsetup_logger(app)\n@app.route('/')\ndef index():\n    app.logger.debug('This is a debug message, visible only in development')\n    app.logger.warning('This warning is logged in production')",
        "detail": "SecureEncoderFlask.src.app",
        "documentation": {}
    },
    {
        "label": "encode_number",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "peekOfCode": "def encode_number(n):\n    \"\"\"Encode a number using a simpler variable-length encoding.\"\"\"\n    bytes = []\n    while n > 127:\n        bytes.insert(0, (n & 0x7F) | 0x80)\n        n >>= 7\n    bytes.insert(0, n & 0x7F)\n    return bytes\ndef lz77_compress(text, window_size=100, min_match_length=3):\n    \"\"\"Compress using LZ77 with reduced overhead for smaller matches.\"\"\"",
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "lz77_compress",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "peekOfCode": "def lz77_compress(text, window_size=100, min_match_length=3):\n    \"\"\"Compress using LZ77 with reduced overhead for smaller matches.\"\"\"\n    if not text:\n        return \"\"\n    i = 0\n    result = bytearray()\n    while i < len(text):\n        max_match = (0, 0)  # (offset, length)\n        if i + min_match_length <= len(text):  # Ensures there is enough data to form a match\n            for j in range(max(i - window_size, 0), i):",
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "lz77_decompress",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "peekOfCode": "def lz77_decompress(compressed):\n    \"\"\"Decompress data that was compressed with LZ77.\"\"\"\n    if not compressed:\n        return \"\"\n    data = base64.b64decode(compressed)\n    result = []\n    i = 0\n    while i < len(data):\n        if data[i] == 255:  # Match flag found\n            i += 1",
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "lzw_compress",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "peekOfCode": "def lzw_compress(input_data):\n    if not input_data:\n        return \"\"\n    dict_size = 256\n    dictionary = {chr(i): i for i in range(dict_size)}\n    w = \"\"\n    compressed = []\n    for c in input_data:\n        wc = w + c\n        if wc in dictionary:",
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "lzw_decompress",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "peekOfCode": "def lzw_decompress(compressed):\n    if not compressed:\n        return \"\"\n    compressed_bytes = base64.b64decode(compressed)\n    dict_size = 256\n    dictionary = {i: chr(i) for i in range(dict_size)}\n    bits = max(dict_size.bit_length(), 8)\n    byte_count = (bits + 7) // 8\n    # Unpack integers according to the bit size used during compression\n    compressed_integers = []",
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "zstd_compress",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "peekOfCode": "def zstd_compress(data):\n    cctx = zstd.ZstdCompressor()\n    compressed_data = cctx.compress(data.encode())\n    return base64.b64encode(compressed_data).decode()\ndef zstd_decompress(compressed):\n    dctx = zstd.ZstdDecompressor()\n    compressed_data = base64.b64decode(compressed)\n    return dctx.decompress(compressed_data).decode()\ndef deflate_compress(data):\n    compressed_data = zlib.compress(data.encode(), level=9)",
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "zstd_decompress",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "peekOfCode": "def zstd_decompress(compressed):\n    dctx = zstd.ZstdDecompressor()\n    compressed_data = base64.b64decode(compressed)\n    return dctx.decompress(compressed_data).decode()\ndef deflate_compress(data):\n    compressed_data = zlib.compress(data.encode(), level=9)\n    return base64.b64encode(compressed_data).decode()\ndef deflate_decompress(compressed):\n    compressed_data = base64.b64decode(compressed)\n    return zlib.decompress(compressed_data).decode()",
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "deflate_compress",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "peekOfCode": "def deflate_compress(data):\n    compressed_data = zlib.compress(data.encode(), level=9)\n    return base64.b64encode(compressed_data).decode()\ndef deflate_decompress(compressed):\n    compressed_data = base64.b64decode(compressed)\n    return zlib.decompress(compressed_data).decode()\ndef brotli_compress(data):\n    compressed_data = brotli.compress(data.encode())\n    return base64.b64encode(compressed_data).decode()\ndef brotli_decompress(compressed):",
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "deflate_decompress",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "peekOfCode": "def deflate_decompress(compressed):\n    compressed_data = base64.b64decode(compressed)\n    return zlib.decompress(compressed_data).decode()\ndef brotli_compress(data):\n    compressed_data = brotli.compress(data.encode())\n    return base64.b64encode(compressed_data).decode()\ndef brotli_decompress(compressed):\n    compressed_data = base64.b64decode(compressed)\n    return brotli.decompress(compressed_data).decode()",
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "brotli_compress",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "peekOfCode": "def brotli_compress(data):\n    compressed_data = brotli.compress(data.encode())\n    return base64.b64encode(compressed_data).decode()\ndef brotli_decompress(compressed):\n    compressed_data = base64.b64decode(compressed)\n    return brotli.decompress(compressed_data).decode()",
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "brotli_decompress",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.compression_decompression",
        "description": "SecureEncoderFlask.src.compression_decompression",
        "peekOfCode": "def brotli_decompress(compressed):\n    compressed_data = base64.b64decode(compressed)\n    return brotli.decompress(compressed_data).decode()",
        "detail": "SecureEncoderFlask.src.compression_decompression",
        "documentation": {}
    },
    {
        "label": "create_app",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.create_app",
        "description": "SecureEncoderFlask.src.create_app",
        "peekOfCode": "def create_app(test_config=None):\n    app = Flask(__name__, instance_relative_config=True)\n    app.config.from_pyfile('config.py')\n    # Default configuration\n    app.config.from_mapping(\n        UPLOAD_FOLDER=os.path.join(app.root_path, 'keys'),\n        ALLOWED_EXTENSIONS={'pem'},\n        MAX_CONTENT_LENGTH=16 * 1024 * 1024,\n        SQLALCHEMY_DATABASE_URI=os.environ.get('DATABASE_URL', 'sqlite:///md5.db'),\n        SQLALCHEMY_TRACK_MODIFICATIONS=False,",
        "detail": "SecureEncoderFlask.src.create_app",
        "documentation": {}
    },
    {
        "label": "setup_logger",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.create_app",
        "description": "SecureEncoderFlask.src.create_app",
        "peekOfCode": "def setup_logger(app):\n    if app.debug:\n        app.logger.setLevel(logging.DEBUG)\n    else:\n        app.logger.setLevel(logging.WARNING)\n        # Create a file handler for production logs\n        file_handler = RotatingFileHandler('production.log', maxBytes=1024 * 1024 * 100, backupCount=10)\n        file_handler.setLevel(logging.WARNING)\n        formatter = logging.Formatter('%(asctime)s %(levelname)s: %(message)s')\n        file_handler.setFormatter(formatter)",
        "detail": "SecureEncoderFlask.src.create_app",
        "documentation": {}
    },
    {
        "label": "encode_base64",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encoder_decoder",
        "description": "SecureEncoderFlask.src.encoder_decoder",
        "peekOfCode": "def encode_base64(input_text: str) -> str:\n    \"\"\"Encode a string using Base64.\"\"\"\n    return base64.b64encode(input_text.encode()).decode()\ndef decode_base64(encoded_text: str) -> str:\n    \"\"\"Decode a Base64 encoded string.\"\"\"\n    return base64.b64decode(encoded_text.encode()).decode()\ndef encode_hex(input_text: str) -> str:\n    \"\"\"Encode a string using Hex encoding.\"\"\"\n    return binascii.hexlify(input_text.encode()).decode()\ndef decode_hex(encoded_text: str) -> str:",
        "detail": "SecureEncoderFlask.src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "decode_base64",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encoder_decoder",
        "description": "SecureEncoderFlask.src.encoder_decoder",
        "peekOfCode": "def decode_base64(encoded_text: str) -> str:\n    \"\"\"Decode a Base64 encoded string.\"\"\"\n    return base64.b64decode(encoded_text.encode()).decode()\ndef encode_hex(input_text: str) -> str:\n    \"\"\"Encode a string using Hex encoding.\"\"\"\n    return binascii.hexlify(input_text.encode()).decode()\ndef decode_hex(encoded_text: str) -> str:\n    \"\"\"Decode a Hex encoded string.\"\"\"\n    return binascii.unhexlify(encoded_text.encode()).decode()\ndef encode_utf8(input_text: str) -> bytes:",
        "detail": "SecureEncoderFlask.src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "encode_hex",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encoder_decoder",
        "description": "SecureEncoderFlask.src.encoder_decoder",
        "peekOfCode": "def encode_hex(input_text: str) -> str:\n    \"\"\"Encode a string using Hex encoding.\"\"\"\n    return binascii.hexlify(input_text.encode()).decode()\ndef decode_hex(encoded_text: str) -> str:\n    \"\"\"Decode a Hex encoded string.\"\"\"\n    return binascii.unhexlify(encoded_text.encode()).decode()\ndef encode_utf8(input_text: str) -> bytes:\n    \"\"\"Encode a string using UTF-8.\"\"\"\n    return input_text.encode('utf-8').hex()\ndef decode_utf8(encoded_text: str) -> str:",
        "detail": "SecureEncoderFlask.src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "decode_hex",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encoder_decoder",
        "description": "SecureEncoderFlask.src.encoder_decoder",
        "peekOfCode": "def decode_hex(encoded_text: str) -> str:\n    \"\"\"Decode a Hex encoded string.\"\"\"\n    return binascii.unhexlify(encoded_text.encode()).decode()\ndef encode_utf8(input_text: str) -> bytes:\n    \"\"\"Encode a string using UTF-8.\"\"\"\n    return input_text.encode('utf-8').hex()\ndef decode_utf8(encoded_text: str) -> str:\n    \"\"\"Decode a UTF-8 encoded byte array.\"\"\"\n    return bytes.fromhex(encoded_text).decode('utf-8')\ndef encode_latin1(input_text: str) -> bytes:",
        "detail": "SecureEncoderFlask.src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "encode_utf8",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encoder_decoder",
        "description": "SecureEncoderFlask.src.encoder_decoder",
        "peekOfCode": "def encode_utf8(input_text: str) -> bytes:\n    \"\"\"Encode a string using UTF-8.\"\"\"\n    return input_text.encode('utf-8').hex()\ndef decode_utf8(encoded_text: str) -> str:\n    \"\"\"Decode a UTF-8 encoded byte array.\"\"\"\n    return bytes.fromhex(encoded_text).decode('utf-8')\ndef encode_latin1(input_text: str) -> bytes:\n    \"\"\"Encode a string using ISO-8859-1 (Latin-1).\"\"\"\n    return input_text.encode('iso-8859-1').hex()\ndef decode_latin1(encoded_text: str) -> str:",
        "detail": "SecureEncoderFlask.src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "decode_utf8",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encoder_decoder",
        "description": "SecureEncoderFlask.src.encoder_decoder",
        "peekOfCode": "def decode_utf8(encoded_text: str) -> str:\n    \"\"\"Decode a UTF-8 encoded byte array.\"\"\"\n    return bytes.fromhex(encoded_text).decode('utf-8')\ndef encode_latin1(input_text: str) -> bytes:\n    \"\"\"Encode a string using ISO-8859-1 (Latin-1).\"\"\"\n    return input_text.encode('iso-8859-1').hex()\ndef decode_latin1(encoded_text: str) -> str:\n    \"\"\"Decode a ISO-8859-1 (Latin-1) encoded byte array.\"\"\"\n    return bytes.fromhex(encoded_text).decode('iso-8859-1')\ndef encode_ascii(input_text: str) -> str:",
        "detail": "SecureEncoderFlask.src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "encode_latin1",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encoder_decoder",
        "description": "SecureEncoderFlask.src.encoder_decoder",
        "peekOfCode": "def encode_latin1(input_text: str) -> bytes:\n    \"\"\"Encode a string using ISO-8859-1 (Latin-1).\"\"\"\n    return input_text.encode('iso-8859-1').hex()\ndef decode_latin1(encoded_text: str) -> str:\n    \"\"\"Decode a ISO-8859-1 (Latin-1) encoded byte array.\"\"\"\n    return bytes.fromhex(encoded_text).decode('iso-8859-1')\ndef encode_ascii(input_text: str) -> str:\n    \"\"\"Encode a string to ASCII values separated by spaces.\"\"\"\n    return ' '.join(str(ord(char)) for char in input_text)\ndef decode_ascii(encoded_text: str) -> str:",
        "detail": "SecureEncoderFlask.src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "decode_latin1",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encoder_decoder",
        "description": "SecureEncoderFlask.src.encoder_decoder",
        "peekOfCode": "def decode_latin1(encoded_text: str) -> str:\n    \"\"\"Decode a ISO-8859-1 (Latin-1) encoded byte array.\"\"\"\n    return bytes.fromhex(encoded_text).decode('iso-8859-1')\ndef encode_ascii(input_text: str) -> str:\n    \"\"\"Encode a string to ASCII values separated by spaces.\"\"\"\n    return ' '.join(str(ord(char)) for char in input_text)\ndef decode_ascii(encoded_text: str) -> str:\n    \"\"\"Decode ASCII values separated by spaces to a string.\"\"\"\n    return ''.join(chr(int(code)) for code in encoded_text.split())\ndef encode_url(input_text: str) -> str:",
        "detail": "SecureEncoderFlask.src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "encode_ascii",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encoder_decoder",
        "description": "SecureEncoderFlask.src.encoder_decoder",
        "peekOfCode": "def encode_ascii(input_text: str) -> str:\n    \"\"\"Encode a string to ASCII values separated by spaces.\"\"\"\n    return ' '.join(str(ord(char)) for char in input_text)\ndef decode_ascii(encoded_text: str) -> str:\n    \"\"\"Decode ASCII values separated by spaces to a string.\"\"\"\n    return ''.join(chr(int(code)) for code in encoded_text.split())\ndef encode_url(input_text: str) -> str:\n    \"\"\"Encode a string for safe URL transmission.\"\"\"\n    return urllib.parse.quote(input_text)\ndef decode_url(encoded_text: str) -> str:",
        "detail": "SecureEncoderFlask.src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "decode_ascii",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encoder_decoder",
        "description": "SecureEncoderFlask.src.encoder_decoder",
        "peekOfCode": "def decode_ascii(encoded_text: str) -> str:\n    \"\"\"Decode ASCII values separated by spaces to a string.\"\"\"\n    return ''.join(chr(int(code)) for code in encoded_text.split())\ndef encode_url(input_text: str) -> str:\n    \"\"\"Encode a string for safe URL transmission.\"\"\"\n    return urllib.parse.quote(input_text)\ndef decode_url(encoded_text: str) -> str:\n    \"\"\"Decode a URL-encoded string.\"\"\"\n    return urllib.parse.unquote(encoded_text)",
        "detail": "SecureEncoderFlask.src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "encode_url",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encoder_decoder",
        "description": "SecureEncoderFlask.src.encoder_decoder",
        "peekOfCode": "def encode_url(input_text: str) -> str:\n    \"\"\"Encode a string for safe URL transmission.\"\"\"\n    return urllib.parse.quote(input_text)\ndef decode_url(encoded_text: str) -> str:\n    \"\"\"Decode a URL-encoded string.\"\"\"\n    return urllib.parse.unquote(encoded_text)",
        "detail": "SecureEncoderFlask.src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "decode_url",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encoder_decoder",
        "description": "SecureEncoderFlask.src.encoder_decoder",
        "peekOfCode": "def decode_url(encoded_text: str) -> str:\n    \"\"\"Decode a URL-encoded string.\"\"\"\n    return urllib.parse.unquote(encoded_text)",
        "detail": "SecureEncoderFlask.src.encoder_decoder",
        "documentation": {}
    },
    {
        "label": "ensure_aes_key",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encryption_decryption",
        "description": "SecureEncoderFlask.src.encryption_decryption",
        "peekOfCode": "def ensure_aes_key(key_file):\n    \"\"\"Ensure there is an AES key available, and return it.\"\"\"\n    if not os.path.exists(key_file):\n        key = os.urandom(32)  # AES-256 key\n        with open(key_file, 'wb') as kf:\n            kf.write(key)\n        print(f\"New AES key generated and saved to {key_file}\")\n    else:\n        with open(key_file, 'rb') as kf:\n            key = kf.read()",
        "detail": "SecureEncoderFlask.src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encryption_decryption",
        "description": "SecureEncoderFlask.src.encryption_decryption",
        "peekOfCode": "def aes_encrypt(plaintext: str, key: bytes):\n    \"\"\"Encrypt a string using AES-GCM encryption with the provided key.\"\"\"\n    # Generate a random nonce\n    nonce = os.urandom(12)\n    # Create an AESGCM object\n    aesgcm = AESGCM(key)\n    # Encrypt the plaintext\n    ciphertext = aesgcm.encrypt(nonce, plaintext.encode(), None)\n    # Return nonce + Ciphertext for decryption\n    return (nonce + ciphertext).hex()",
        "detail": "SecureEncoderFlask.src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encryption_decryption",
        "description": "SecureEncoderFlask.src.encryption_decryption",
        "peekOfCode": "def aes_decrypt(ciphertext_hex: str, key: bytes):\n    \"\"\"Decrypt a string using AES-GCM decryption with the provided key.\"\"\"\n    ciphertext = bytes.fromhex(ciphertext_hex)\n    # Extract nonce from the beginning of the ciphertext\n    nonce = ciphertext[:12]\n    actual_ciphertext = ciphertext[12:]\n    # Create an AESGCM object\n    aesgcm = AESGCM(key)\n    # Decrypt the ciphertext\n    try:",
        "detail": "SecureEncoderFlask.src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "generate_rsa_keys",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encryption_decryption",
        "description": "SecureEncoderFlask.src.encryption_decryption",
        "peekOfCode": "def generate_rsa_keys():\n    \"\"\"Generate RSA private and public keys.\"\"\"\n    private_key = rsa.generate_private_key(\n        public_exponent=65537,\n        key_size=2048,\n        backend=default_backend()\n    )\n    public_key = private_key.public_key()\n    return private_key, public_key\ndef save_rsa_key(key, key_file, is_private=True):",
        "detail": "SecureEncoderFlask.src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "save_rsa_key",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encryption_decryption",
        "description": "SecureEncoderFlask.src.encryption_decryption",
        "peekOfCode": "def save_rsa_key(key, key_file, is_private=True):\n    \"\"\"Save an RSA key (private or public) to a file.\"\"\"\n    with open(key_file, \"wb\") as kf:\n        if is_private:\n            kf.write(key.private_bytes(\n                encoding=serialization.Encoding.PEM,\n                format=serialization.PrivateFormat.PKCS8,\n                encryption_algorithm=serialization.NoEncryption()\n            ))\n        else:",
        "detail": "SecureEncoderFlask.src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "ensure_rsa_public_key",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encryption_decryption",
        "description": "SecureEncoderFlask.src.encryption_decryption",
        "peekOfCode": "def ensure_rsa_public_key(public_key_file):\n    \"\"\"Ensure the RSA public key is available and return it.\"\"\"\n    if not os.path.exists(public_key_file):\n        # If the public key is missing, generate both keys to ensure matching pairs\n        private_key_file = public_key_file.replace(\"public\", \"private\")\n        if not os.path.exists(private_key_file):\n            private_key, public_key = generate_rsa_keys()\n            save_rsa_key(private_key, private_key_file, is_private=True)\n            save_rsa_key(public_key, public_key_file, is_private=False)\n        else:",
        "detail": "SecureEncoderFlask.src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "ensure_rsa_private_key",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encryption_decryption",
        "description": "SecureEncoderFlask.src.encryption_decryption",
        "peekOfCode": "def ensure_rsa_private_key(private_key_file):\n    \"\"\"Ensure the RSA private key is available and return it.\"\"\"\n    if not os.path.exists(private_key_file):\n        # If the private key is missing, generate both keys to ensure matching pairs\n        public_key_file = private_key_file.replace(\"private\", \"public\")\n        private_key, public_key = generate_rsa_keys()\n        save_rsa_key(private_key, private_key_file, is_private=True)\n        save_rsa_key(public_key, public_key_file, is_private=False)\n    else:\n        # Load the existing private key",
        "detail": "SecureEncoderFlask.src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "rsa_encrypt",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encryption_decryption",
        "description": "SecureEncoderFlask.src.encryption_decryption",
        "peekOfCode": "def rsa_encrypt(plaintext: str, public_key):\n    \"\"\"Encrypt a string using RSA public key.\"\"\"\n    ciphertext = public_key.encrypt(\n        plaintext.encode(),\n        padding.OAEP(\n            mgf=padding.MGF1(algorithm=hashes.SHA256()),\n            algorithm=hashes.SHA256(),\n            label=None\n        )\n    )",
        "detail": "SecureEncoderFlask.src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "rsa_decrypt",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.encryption_decryption",
        "description": "SecureEncoderFlask.src.encryption_decryption",
        "peekOfCode": "def rsa_decrypt(ciphertext_hex: str, private_key):\n    \"\"\"Decrypt a string using RSA private key.\"\"\"\n    ciphertext = bytes.fromhex(ciphertext_hex)\n    plaintext = private_key.decrypt(\n        ciphertext,\n        padding.OAEP(\n            mgf=padding.MGF1(algorithm=hashes.SHA256()),\n            algorithm=hashes.SHA256(),\n            label=None\n        )",
        "detail": "SecureEncoderFlask.src.encryption_decryption",
        "documentation": {}
    },
    {
        "label": "HuffmanCoding",
        "kind": 6,
        "importPath": "SecureEncoderFlask.src.huffman",
        "description": "SecureEncoderFlask.src.huffman",
        "peekOfCode": "class HuffmanCoding:\n    class Node:\n        def __init__(self, char=None, freq=None):\n            self.char = char\n            self.freq = freq\n            self.left = None\n            self.right = None\n        def __lt__(self, other):\n            return self.freq < other.freq\n    def __init__(self):",
        "detail": "SecureEncoderFlask.src.huffman",
        "documentation": {}
    },
    {
        "label": "huffman_compress",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.huffman",
        "description": "SecureEncoderFlask.src.huffman",
        "peekOfCode": "def huffman_compress(data):\n    huffman_algorithm = HuffmanCoding()\n    return huffman_algorithm.compress(data)\ndef huffman_decompress(data):\n    huffman_algorithm = HuffmanCoding()\n    return huffman_algorithm.decompress(data)\nclass HuffmanCoding:\n    class Node:\n        def __init__(self, char=None, freq=None):\n            self.char = char",
        "detail": "SecureEncoderFlask.src.huffman",
        "documentation": {}
    },
    {
        "label": "huffman_decompress",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.huffman",
        "description": "SecureEncoderFlask.src.huffman",
        "peekOfCode": "def huffman_decompress(data):\n    huffman_algorithm = HuffmanCoding()\n    return huffman_algorithm.decompress(data)\nclass HuffmanCoding:\n    class Node:\n        def __init__(self, char=None, freq=None):\n            self.char = char\n            self.freq = freq\n            self.left = None\n            self.right = None",
        "detail": "SecureEncoderFlask.src.huffman",
        "documentation": {}
    },
    {
        "label": "MD5Hash",
        "kind": 6,
        "importPath": "SecureEncoderFlask.src.md5_model",
        "description": "SecureEncoderFlask.src.md5_model",
        "peekOfCode": "class MD5Hash(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    text = db.Column(db.String(255), unique=True, nullable=False)\n    md5_hash = db.Column(db.String(32), unique=True, nullable=False)\n    def __init__(self, text, md5_hash):\n        self.text = text\n        self.md5_hash = md5_hash\ndef md5_encode(text):\n    hash_object = hashlib.md5(text.encode())\n    hash_hex = hash_object.hexdigest()",
        "detail": "SecureEncoderFlask.src.md5_model",
        "documentation": {}
    },
    {
        "label": "md5_encode",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.md5_model",
        "description": "SecureEncoderFlask.src.md5_model",
        "peekOfCode": "def md5_encode(text):\n    hash_object = hashlib.md5(text.encode())\n    hash_hex = hash_object.hexdigest()\n    existing_hash = MD5Hash.query.filter_by(md5_hash=hash_hex).first()\n    if not existing_hash:\n        new_hash = MD5Hash(text, hash_hex)\n        db.session.add(new_hash)\n        db.session.commit()\n    return hash_hex\ndef md5_decode(hash_hex):",
        "detail": "SecureEncoderFlask.src.md5_model",
        "documentation": {}
    },
    {
        "label": "md5_decode",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.md5_model",
        "description": "SecureEncoderFlask.src.md5_model",
        "peekOfCode": "def md5_decode(hash_hex):\n    match = MD5Hash.query.filter_by(md5_hash=hash_hex).first()\n    if match:\n        return match.text\n    return \"No match found\"\ndef populate_db(faker, num_entries=1000):\n    for _ in range(num_entries):\n        sentence = faker.sentence()\n        md5_encode(sentence)",
        "detail": "SecureEncoderFlask.src.md5_model",
        "documentation": {}
    },
    {
        "label": "populate_db",
        "kind": 2,
        "importPath": "SecureEncoderFlask.src.md5_model",
        "description": "SecureEncoderFlask.src.md5_model",
        "peekOfCode": "def populate_db(faker, num_entries=1000):\n    for _ in range(num_entries):\n        sentence = faker.sentence()\n        md5_encode(sentence)",
        "detail": "SecureEncoderFlask.src.md5_model",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "SecureEncoderFlask.src.md5_model",
        "description": "SecureEncoderFlask.src.md5_model",
        "peekOfCode": "db = SQLAlchemy()\nclass MD5Hash(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    text = db.Column(db.String(255), unique=True, nullable=False)\n    md5_hash = db.Column(db.String(32), unique=True, nullable=False)\n    def __init__(self, text, md5_hash):\n        self.text = text\n        self.md5_hash = md5_hash\ndef md5_encode(text):\n    hash_object = hashlib.md5(text.encode())",
        "detail": "SecureEncoderFlask.src.md5_model",
        "documentation": {}
    },
    {
        "label": "test_lz77_compression_cycle",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_compression_decompression",
        "description": "SecureEncoderFlask.tests.test_compression_decompression",
        "peekOfCode": "def test_lz77_compression_cycle():\n    \"\"\"Test LZ77 compression and decompression.\"\"\"\n    compressed = lz77_compress(TEST_TEXT)\n    decompressed = lz77_decompress(compressed)\n    assert decompressed == TEST_TEXT, \"LZ77 decompression does not match the original\"\ndef test_lzw_compression_cycle():\n    \"\"\"Test LZW compression and decompression.\"\"\"\n    compressed = lzw_compress(TEST_TEXT)\n    decompressed = lzw_decompress(compressed)\n    assert decompressed == TEST_TEXT, \"LZW decompression does not match the original\"",
        "detail": "SecureEncoderFlask.tests.test_compression_decompression",
        "documentation": {}
    },
    {
        "label": "test_lzw_compression_cycle",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_compression_decompression",
        "description": "SecureEncoderFlask.tests.test_compression_decompression",
        "peekOfCode": "def test_lzw_compression_cycle():\n    \"\"\"Test LZW compression and decompression.\"\"\"\n    compressed = lzw_compress(TEST_TEXT)\n    decompressed = lzw_decompress(compressed)\n    assert decompressed == TEST_TEXT, \"LZW decompression does not match the original\"\ndef test_zstd_compression_cycle():\n    \"\"\"Test Zstandard compression and decompression.\"\"\"\n    compressed = zstd_compress(TEST_TEXT)\n    decompressed = zstd_decompress(compressed)\n    assert decompressed == TEST_TEXT, \"Zstd decompression does not match the original\"",
        "detail": "SecureEncoderFlask.tests.test_compression_decompression",
        "documentation": {}
    },
    {
        "label": "test_zstd_compression_cycle",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_compression_decompression",
        "description": "SecureEncoderFlask.tests.test_compression_decompression",
        "peekOfCode": "def test_zstd_compression_cycle():\n    \"\"\"Test Zstandard compression and decompression.\"\"\"\n    compressed = zstd_compress(TEST_TEXT)\n    decompressed = zstd_decompress(compressed)\n    assert decompressed == TEST_TEXT, \"Zstd decompression does not match the original\"\ndef test_deflate_compression_cycle():\n    \"\"\"Test Deflate compression and decompression.\"\"\"\n    compressed = deflate_compress(TEST_TEXT)\n    decompressed = deflate_decompress(compressed)\n    assert decompressed == TEST_TEXT, \"Deflate decompression does not match the original\"",
        "detail": "SecureEncoderFlask.tests.test_compression_decompression",
        "documentation": {}
    },
    {
        "label": "test_deflate_compression_cycle",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_compression_decompression",
        "description": "SecureEncoderFlask.tests.test_compression_decompression",
        "peekOfCode": "def test_deflate_compression_cycle():\n    \"\"\"Test Deflate compression and decompression.\"\"\"\n    compressed = deflate_compress(TEST_TEXT)\n    decompressed = deflate_decompress(compressed)\n    assert decompressed == TEST_TEXT, \"Deflate decompression does not match the original\"\ndef test_brotli_compression_cycle():\n    \"\"\"Test Brotli compression and decompression.\"\"\"\n    compressed = brotli_compress(TEST_TEXT)\n    decompressed = brotli_decompress(compressed)\n    assert decompressed == TEST_TEXT, \"Brotli decompression does not match the original\"",
        "detail": "SecureEncoderFlask.tests.test_compression_decompression",
        "documentation": {}
    },
    {
        "label": "test_brotli_compression_cycle",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_compression_decompression",
        "description": "SecureEncoderFlask.tests.test_compression_decompression",
        "peekOfCode": "def test_brotli_compression_cycle():\n    \"\"\"Test Brotli compression and decompression.\"\"\"\n    compressed = brotli_compress(TEST_TEXT)\n    decompressed = brotli_decompress(compressed)\n    assert decompressed == TEST_TEXT, \"Brotli decompression does not match the original\"\n# Additional tests for edge cases\n@pytest.mark.parametrize(\"text\", [\"\", \"a\", TEST_TEXT, SPECIAL_TEST_TEXT])\ndef test_compression_with_varied_text(text):\n    \"\"\"Test compression algorithms with varied text inputs.\"\"\"\n    functions = [",
        "detail": "SecureEncoderFlask.tests.test_compression_decompression",
        "documentation": {}
    },
    {
        "label": "test_compression_with_varied_text",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_compression_decompression",
        "description": "SecureEncoderFlask.tests.test_compression_decompression",
        "peekOfCode": "def test_compression_with_varied_text(text):\n    \"\"\"Test compression algorithms with varied text inputs.\"\"\"\n    functions = [\n        (lz77_compress, lz77_decompress),\n        (lzw_compress, lzw_decompress),\n        (zstd_compress, zstd_decompress),\n        (deflate_compress, deflate_decompress),\n        (brotli_compress, brotli_decompress)\n    ]\n    for compress, decompress in functions:",
        "detail": "SecureEncoderFlask.tests.test_compression_decompression",
        "documentation": {}
    },
    {
        "label": "TEST_TEXT",
        "kind": 5,
        "importPath": "SecureEncoderFlask.tests.test_compression_decompression",
        "description": "SecureEncoderFlask.tests.test_compression_decompression",
        "peekOfCode": "TEST_TEXT = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed non risus. Suspendisse lectus tortor, dignissim sit amet, adipiscing nec, ultricies sed, dolor. Cras elementum ultrices diam. Maecenas ligula massa, varius a, semper congue, euismod non, mi. Proin porttitor, orci nec nonummy molestie, enim est eleifend mi, non fermentum diam nisl sit amet erat. Duis semper. Duis arcu massa, scelerisque vitae, consequat in, pretium a, enim. Pellentesque congue. Ut in risus volutpat libero pharetra tempor. Cras vestibulum bibendum augue. Praesent egestas leo in pede. Praesent blandit odio eu enim. Pellentesque sed dui ut augue blandit sodales. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Aliquam nibh. Mauris ac mauris sed pede pellentesque fermentum. Maecenas adipiscing ante non diam sodales hendrerit.\"\nSPECIAL_TEST_TEXT = \"~!#$%^&*()_+\"\ndef test_lz77_compression_cycle():\n    \"\"\"Test LZ77 compression and decompression.\"\"\"\n    compressed = lz77_compress(TEST_TEXT)\n    decompressed = lz77_decompress(compressed)\n    assert decompressed == TEST_TEXT, \"LZ77 decompression does not match the original\"\ndef test_lzw_compression_cycle():\n    \"\"\"Test LZW compression and decompression.\"\"\"\n    compressed = lzw_compress(TEST_TEXT)",
        "detail": "SecureEncoderFlask.tests.test_compression_decompression",
        "documentation": {}
    },
    {
        "label": "SPECIAL_TEST_TEXT",
        "kind": 5,
        "importPath": "SecureEncoderFlask.tests.test_compression_decompression",
        "description": "SecureEncoderFlask.tests.test_compression_decompression",
        "peekOfCode": "SPECIAL_TEST_TEXT = \"~!#$%^&*()_+\"\ndef test_lz77_compression_cycle():\n    \"\"\"Test LZ77 compression and decompression.\"\"\"\n    compressed = lz77_compress(TEST_TEXT)\n    decompressed = lz77_decompress(compressed)\n    assert decompressed == TEST_TEXT, \"LZ77 decompression does not match the original\"\ndef test_lzw_compression_cycle():\n    \"\"\"Test LZW compression and decompression.\"\"\"\n    compressed = lzw_compress(TEST_TEXT)\n    decompressed = lzw_decompress(compressed)",
        "detail": "SecureEncoderFlask.tests.test_compression_decompression",
        "documentation": {}
    },
    {
        "label": "test_encode_base64",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encoder_decoder",
        "description": "SecureEncoderFlask.tests.test_encoder_decoder",
        "peekOfCode": "def test_encode_base64():\n    \"\"\"Test Base64 encoding of a string.\"\"\"\n    input_text = \"Hello, World!\"\n    expected_output = \"SGVsbG8sIFdvcmxkIQ==\"\n    assert encode_base64(input_text) == expected_output, \"Base64 encoding failed\"\ndef test_decode_base64():\n    \"\"\"Test decoding of a Base64-encoded string.\"\"\"\n    encoded_text = \"SGVsbG8sIFdvcmxkIQ==\"\n    expected_output = \"Hello, World!\"\n    assert decode_base64(encoded_text) == expected_output, \"Base64 decoding failed\"",
        "detail": "SecureEncoderFlask.tests.test_encoder_decoder",
        "documentation": {}
    },
    {
        "label": "test_decode_base64",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encoder_decoder",
        "description": "SecureEncoderFlask.tests.test_encoder_decoder",
        "peekOfCode": "def test_decode_base64():\n    \"\"\"Test decoding of a Base64-encoded string.\"\"\"\n    encoded_text = \"SGVsbG8sIFdvcmxkIQ==\"\n    expected_output = \"Hello, World!\"\n    assert decode_base64(encoded_text) == expected_output, \"Base64 decoding failed\"\ndef test_encode_hex():\n    \"\"\"Test Hex encoding of a string.\"\"\"\n    input_text = \"Hello, World!\"\n    expected_output = \"48656c6c6f2c20576f726c6421\"\n    assert encode_hex(input_text) == expected_output, \"Hex encoding failed\"",
        "detail": "SecureEncoderFlask.tests.test_encoder_decoder",
        "documentation": {}
    },
    {
        "label": "test_encode_hex",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encoder_decoder",
        "description": "SecureEncoderFlask.tests.test_encoder_decoder",
        "peekOfCode": "def test_encode_hex():\n    \"\"\"Test Hex encoding of a string.\"\"\"\n    input_text = \"Hello, World!\"\n    expected_output = \"48656c6c6f2c20576f726c6421\"\n    assert encode_hex(input_text) == expected_output, \"Hex encoding failed\"\ndef test_decode_hex():\n    \"\"\"Test decoding of a Hex-encoded string.\"\"\"\n    encoded_text = \"48656c6c6f2c20576f726c6421\"\n    expected_output = \"Hello, World!\"\n    assert decode_hex(encoded_text) == expected_output, \"Hex decoding failed\"",
        "detail": "SecureEncoderFlask.tests.test_encoder_decoder",
        "documentation": {}
    },
    {
        "label": "test_decode_hex",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encoder_decoder",
        "description": "SecureEncoderFlask.tests.test_encoder_decoder",
        "peekOfCode": "def test_decode_hex():\n    \"\"\"Test decoding of a Hex-encoded string.\"\"\"\n    encoded_text = \"48656c6c6f2c20576f726c6421\"\n    expected_output = \"Hello, World!\"\n    assert decode_hex(encoded_text) == expected_output, \"Hex decoding failed\"\ndef test_encode_utf8():\n    \"\"\"Test UTF-8 encoding of a string.\"\"\"\n    input_text = \"Hello, World!\"\n    expected_output = \"48656c6c6f2c20576f726c6421\"\n    encoded_text = encode_utf8(input_text)",
        "detail": "SecureEncoderFlask.tests.test_encoder_decoder",
        "documentation": {}
    },
    {
        "label": "test_encode_utf8",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encoder_decoder",
        "description": "SecureEncoderFlask.tests.test_encoder_decoder",
        "peekOfCode": "def test_encode_utf8():\n    \"\"\"Test UTF-8 encoding of a string.\"\"\"\n    input_text = \"Hello, World!\"\n    expected_output = \"48656c6c6f2c20576f726c6421\"\n    encoded_text = encode_utf8(input_text)\n    assert encoded_text == expected_output, f\"UTF-8 encoding failed: {encoded_text} != {expected_output}\"\ndef test_decode_utf8():\n    \"\"\"Test decoding of a UTF-8 encoded byte array.\"\"\"\n    input_bytes = \"48656c6c6f2c20576f726c6421\"\n    expected_output = \"Hello, World!\"",
        "detail": "SecureEncoderFlask.tests.test_encoder_decoder",
        "documentation": {}
    },
    {
        "label": "test_decode_utf8",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encoder_decoder",
        "description": "SecureEncoderFlask.tests.test_encoder_decoder",
        "peekOfCode": "def test_decode_utf8():\n    \"\"\"Test decoding of a UTF-8 encoded byte array.\"\"\"\n    input_bytes = \"48656c6c6f2c20576f726c6421\"\n    expected_output = \"Hello, World!\"\n    output_text = decode_utf8(input_bytes)\n    assert output_text == expected_output, f\"UTF-8 decoding failed: {output_text} != {expected_output}\"\ndef test_encode_latin1():\n    \"\"\"Test Latin-1 encoding of a string.\"\"\"\n    input_text = \"Caf\"\n    expected_output = \"436166e9\"",
        "detail": "SecureEncoderFlask.tests.test_encoder_decoder",
        "documentation": {}
    },
    {
        "label": "test_encode_latin1",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encoder_decoder",
        "description": "SecureEncoderFlask.tests.test_encoder_decoder",
        "peekOfCode": "def test_encode_latin1():\n    \"\"\"Test Latin-1 encoding of a string.\"\"\"\n    input_text = \"Caf\"\n    expected_output = \"436166e9\"\n    encoded_text = encode_latin1(input_text)\n    assert encoded_text == expected_output, f\"Latin-1 encoding failed: {encoded_text} != {expected_output}\"\ndef test_decode_latin1():\n    \"\"\"Test decoding of a Latin-1 encoded byte array.\"\"\"\n    input_bytes = \"436166e9\"\n    expected_output = \"Caf\"",
        "detail": "SecureEncoderFlask.tests.test_encoder_decoder",
        "documentation": {}
    },
    {
        "label": "test_decode_latin1",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encoder_decoder",
        "description": "SecureEncoderFlask.tests.test_encoder_decoder",
        "peekOfCode": "def test_decode_latin1():\n    \"\"\"Test decoding of a Latin-1 encoded byte array.\"\"\"\n    input_bytes = \"436166e9\"\n    expected_output = \"Caf\"\n    output_text = decode_latin1(input_bytes)\n    assert output_text == expected_output, f\"Latin-1 decoding failed: {output_text} != {expected_output}\"\ndef test_encode_ascii():\n    \"\"\"Test ASCII encoding of a string.\"\"\"\n    input_text = \"Hello, World!\"\n    expected_output = \"72 101 108 108 111 44 32 87 111 114 108 100 33\"",
        "detail": "SecureEncoderFlask.tests.test_encoder_decoder",
        "documentation": {}
    },
    {
        "label": "test_encode_ascii",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encoder_decoder",
        "description": "SecureEncoderFlask.tests.test_encoder_decoder",
        "peekOfCode": "def test_encode_ascii():\n    \"\"\"Test ASCII encoding of a string.\"\"\"\n    input_text = \"Hello, World!\"\n    expected_output = \"72 101 108 108 111 44 32 87 111 114 108 100 33\"\n    encoded_text = encode_ascii(input_text)\n    assert encoded_text == expected_output, f\"ASCII encoding failed: {encoded_text} != {expected_output}\"\ndef test_decode_ascii():\n    \"\"\"Test decoding of an ASCII-encoded string.\"\"\"\n    encoded_text = \"72 101 108 108 111 44 32 87 111 114 108 100 33\"\n    expected_output = \"Hello, World!\"",
        "detail": "SecureEncoderFlask.tests.test_encoder_decoder",
        "documentation": {}
    },
    {
        "label": "test_decode_ascii",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encoder_decoder",
        "description": "SecureEncoderFlask.tests.test_encoder_decoder",
        "peekOfCode": "def test_decode_ascii():\n    \"\"\"Test decoding of an ASCII-encoded string.\"\"\"\n    encoded_text = \"72 101 108 108 111 44 32 87 111 114 108 100 33\"\n    expected_output = \"Hello, World!\"\n    output_text = decode_ascii(encoded_text)\n    assert output_text == expected_output, f\"ASCII decoding failed: {output_text} != {expected_output}\"\ndef test_encode_url():\n    \"\"\"Test URL encoding of a string.\"\"\"\n    input_text = \"Hello, World! @2023\"\n    expected_output = \"Hello%2C%20World%21%20%402023\"",
        "detail": "SecureEncoderFlask.tests.test_encoder_decoder",
        "documentation": {}
    },
    {
        "label": "test_encode_url",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encoder_decoder",
        "description": "SecureEncoderFlask.tests.test_encoder_decoder",
        "peekOfCode": "def test_encode_url():\n    \"\"\"Test URL encoding of a string.\"\"\"\n    input_text = \"Hello, World! @2023\"\n    expected_output = \"Hello%2C%20World%21%20%402023\"\n    encoded_text = encode_url(input_text)\n    assert encoded_text == expected_output, f\"URL encoding failed: {encoded_text} != {expected_output}\"\ndef test_decode_url():\n    \"\"\"Test decoding of a URL-encoded string.\"\"\"\n    encoded_text = \"Hello%2C%20World%21%20%402023\"\n    expected_output = \"Hello, World! @2023\"",
        "detail": "SecureEncoderFlask.tests.test_encoder_decoder",
        "documentation": {}
    },
    {
        "label": "test_decode_url",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encoder_decoder",
        "description": "SecureEncoderFlask.tests.test_encoder_decoder",
        "peekOfCode": "def test_decode_url():\n    \"\"\"Test decoding of a URL-encoded string.\"\"\"\n    encoded_text = \"Hello%2C%20World%21%20%402023\"\n    expected_output = \"Hello, World! @2023\"\n    output_text = decode_url(encoded_text)\n    assert output_text == expected_output, f\"URL decoding failed: {output_text} != {expected_output}\"",
        "detail": "SecureEncoderFlask.tests.test_encoder_decoder",
        "documentation": {}
    },
    {
        "label": "setup_module",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def setup_module(module):\n    \"\"\" Setup any state specific to the execution of the given module.\"\"\"\n    global original_key_file\n    original_key_file = \"aes_key.bin\"  # This should match your production key file path\n    global test_key_file\n    test_key_file = \"tests/test_aes_key.bin\"\n    # Ensure the test directory exists\n    os.makedirs(os.path.dirname(test_key_file), exist_ok=True)\ndef teardown_module(module):\n    \"\"\" Teardown any state that was previously setup with a setup_module method.\"\"\"",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "teardown_module",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def teardown_module(module):\n    \"\"\" Teardown any state that was previously setup with a setup_module method.\"\"\"\n    if os.path.exists(test_key_file):\n        os.remove(test_key_file)\ndef test_ensure_aes_key_generation():\n    \"\"\"Test that a new key is generated when the key file is missing.\"\"\"\n    if os.path.exists(test_key_file):\n        os.remove(test_key_file)  # Ensure the key file is not present before the test\n    assert not os.path.exists(test_key_file), \"Key file should not exist before the test\"\n    key = ensure_aes_key(test_key_file)",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_ensure_aes_key_generation",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_ensure_aes_key_generation():\n    \"\"\"Test that a new key is generated when the key file is missing.\"\"\"\n    if os.path.exists(test_key_file):\n        os.remove(test_key_file)  # Ensure the key file is not present before the test\n    assert not os.path.exists(test_key_file), \"Key file should not exist before the test\"\n    key = ensure_aes_key(test_key_file)\n    assert os.path.exists(test_key_file), \"Key file should be created after calling ensure_aes_key\"\n    with open(test_key_file, 'rb') as f:\n        assert f.read() == key, \"Key file should contain the generated key\"\ndef test_ensure_aes_key_retrieval():",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_ensure_aes_key_retrieval",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_ensure_aes_key_retrieval():\n    \"\"\"Test that an existing key is retrieved when the key file is present.\"\"\"\n    key = os.urandom(32)\n    with open(test_key_file, 'wb') as f:\n        f.write(key)\n    assert os.path.exists(test_key_file), \"Key file should exist before the test\"\n    retrieved_key = ensure_aes_key(test_key_file)\n    assert retrieved_key == key, \"Retrieved key should match the one in the key file\"\ndef test_aes_encrypt_decrypt():\n    \"\"\"Test that text is correctly encrypted and decrypted back to its original form.\"\"\"",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_decrypt",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_aes_encrypt_decrypt():\n    \"\"\"Test that text is correctly encrypted and decrypted back to its original form.\"\"\"\n    key = ensure_aes_key(test_key_file)  # Use the helper function to manage the key\n    plaintext = \"Hello, World!\"\n    encrypted = aes_encrypt(plaintext, key)\n    decrypted = aes_decrypt(encrypted, key)\n    assert decrypted == plaintext, \"Decrypted text should match the original\"\ndef test_aes_encryption_decryption_empty_string():\n    \"\"\"Test encryption and decryption of an empty string.\"\"\"\n    key = ensure_aes_key(test_key_file)",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_aes_encryption_decryption_empty_string",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_aes_encryption_decryption_empty_string():\n    \"\"\"Test encryption and decryption of an empty string.\"\"\"\n    key = ensure_aes_key(test_key_file)\n    plaintext = \"\"\n    encrypted = aes_encrypt(plaintext, key)\n    decrypted = aes_decrypt(encrypted, key)\n    assert decrypted == plaintext, \"Decrypted text should be an empty string for empty input\"\ndef test_aes_encryption_uniqueness():\n    \"\"\"Test that encrypting the same text with different keys or nonces results in different ciphertexts.\"\"\"\n    plaintext = \"Repeatable text\"",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_aes_encryption_uniqueness",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_aes_encryption_uniqueness():\n    \"\"\"Test that encrypting the same text with different keys or nonces results in different ciphertexts.\"\"\"\n    plaintext = \"Repeatable text\"\n    key1 = ensure_aes_key(test_key_file)\n    key2 = os.urandom(32)  # Ensure a different key\n    encrypted1 = aes_encrypt(plaintext, key1)\n    encrypted2 = aes_encrypt(plaintext, key2)\n    assert encrypted1 != encrypted2, \"Encryption with different keys should produce different outputs\"\n    # Test with the same key but expect different nonces to generate different ciphertexts\n    encrypted3 = aes_encrypt(plaintext, key1)",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_aes_encryption_decryption_invalid_key",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_aes_encryption_decryption_invalid_key():\n    \"\"\"Test that decryption fails with an incorrect key.\"\"\"\n    key = ensure_aes_key(test_key_file)\n    plaintext = \"Secret message\"\n    encrypted = aes_encrypt(plaintext, key)\n    wrong_key = os.urandom(32)  # Ensure a different key\n    with pytest.raises(ValueError) as excinfo:\n        decrypted = aes_decrypt(encrypted, wrong_key)\n    assert \"Decryption failed or wrong key used\" in str(excinfo.value), \"Decryption should fail with an incorrect key and raise a ValueError\"\ndef test_rsa_encrypt_decrypt():",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_rsa_encrypt_decrypt",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_rsa_encrypt_decrypt():\n    \"\"\"Test that text is correctly encrypted and decrypted back to its original form using RSA.\"\"\"\n    private_key, public_key = generate_rsa_keys()\n    plaintext = \"Hello, RSA World!\"\n    encrypted = rsa_encrypt(plaintext, public_key)\n    decrypted = rsa_decrypt(encrypted, private_key)\n    assert decrypted == plaintext, \"Decrypted text should match the original plaintext\"\ndef test_rsa_encryption_uniqueness():\n    \"\"\"Test that RSA encryption of the same text results in different ciphertexts.\"\"\"\n    _, public_key = generate_rsa_keys()",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_rsa_encryption_uniqueness",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_rsa_encryption_uniqueness():\n    \"\"\"Test that RSA encryption of the same text results in different ciphertexts.\"\"\"\n    _, public_key = generate_rsa_keys()\n    plaintext = \"Repeatable text\"\n    encrypted1 = rsa_encrypt(plaintext, public_key)\n    encrypted2 = rsa_encrypt(plaintext, public_key)\n    assert encrypted1 != encrypted2, \"RSA encryption should produce different outputs for the same input\"\ndef test_rsa_encrypt_decrypt_with_multiple_keys():\n    \"\"\"Test RSA encryption and decryption using multiple key pairs.\"\"\"\n    private_key1, public_key1 = generate_rsa_keys()",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_rsa_encrypt_decrypt_with_multiple_keys",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_rsa_encrypt_decrypt_with_multiple_keys():\n    \"\"\"Test RSA encryption and decryption using multiple key pairs.\"\"\"\n    private_key1, public_key1 = generate_rsa_keys()\n    private_key2, public_key2 = generate_rsa_keys()\n    plaintext = \"Shared Secret!\"\n    encrypted_with_key1 = rsa_encrypt(plaintext, public_key1)\n    decrypted_with_key1 = rsa_decrypt(encrypted_with_key1, private_key1)\n    encrypted_with_key2 = rsa_encrypt(plaintext, public_key2)\n    decrypted_with_key2 = rsa_decrypt(encrypted_with_key2, private_key2)\n    assert decrypted_with_key1 == plaintext, \"Decrypted text should match the original with key pair 1\"",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_rsa_large_data_encryption",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_rsa_large_data_encryption():\n    \"\"\"Test RSA encryption and decryption with a chunking approach (demonstrative).\"\"\"\n    private_key, public_key = generate_rsa_keys()\n    plaintext = \"A\" * 1000  # Demonstrative chunking\n    chunk_size = 190  # Based on RSA key size minus padding overhead\n    encrypted_chunks = [rsa_encrypt(plaintext[i:i+chunk_size], public_key) for i in range(0, len(plaintext), chunk_size)]\n    decrypted_chunks = [rsa_decrypt(chunk, private_key) for chunk in encrypted_chunks]\n    decrypted_text = ''.join(decrypted_chunks)\n    assert decrypted_text == plaintext, \"Decrypted text should match the original large plaintext\"\ndef test_rsa_decryption_with_wrong_key():",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_rsa_decryption_with_wrong_key",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_rsa_decryption_with_wrong_key():\n    \"\"\"Test RSA decryption fails when using a wrong private key.\"\"\"\n    private_key1, public_key1 = generate_rsa_keys()\n    private_key2, _ = generate_rsa_keys()  # Correct private key is not used\n    plaintext = \"Critical data\"\n    encrypted = rsa_encrypt(plaintext, public_key1)\n    try:\n        rsa_decrypt(encrypted, private_key2)\n        assert False, \"Decryption should fail but succeeded\"\n    except Exception as e:",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_rsa_public_key_reuse",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_rsa_public_key_reuse():\n    \"\"\"Test reusing the same public key for multiple encryptions.\"\"\"\n    private_key, public_key = generate_rsa_keys()\n    plaintexts = [\"Message 1\", \"Message 2\", \"Message 3\"]\n    encrypted_texts = [rsa_encrypt(pt, public_key) for pt in plaintexts]\n    decrypted_texts = [rsa_decrypt(et, private_key) for et in encrypted_texts]\n    assert all(dt == pt for dt, pt in zip(decrypted_texts, plaintexts)), \"All decrypted texts should match their original plaintexts\"\ndef test_rsa_padding_oracle_attack_scenario():\n    \"\"\"Simulate a scenario that should be resistant to padding oracle attacks.\"\"\"\n    private_key, public_key = generate_rsa_keys()",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_rsa_padding_oracle_attack_scenario",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_encryption_decryption",
        "description": "SecureEncoderFlask.tests.test_encryption_decryption",
        "peekOfCode": "def test_rsa_padding_oracle_attack_scenario():\n    \"\"\"Simulate a scenario that should be resistant to padding oracle attacks.\"\"\"\n    private_key, public_key = generate_rsa_keys()\n    plaintext = \"Very sensitive data\"\n    encrypted = rsa_encrypt(plaintext, public_key)\n    # Correct XOR operation for tampering demonstration\n    encrypted_bytes = bytes.fromhex(encrypted)\n    tampered_ciphertext = encrypted_bytes[:-1] + bytes([encrypted_bytes[-1] ^ 0x01])\n    tampered_hex = tampered_ciphertext.hex()\n    try:",
        "detail": "SecureEncoderFlask.tests.test_encryption_decryption",
        "documentation": {}
    },
    {
        "label": "test_huffman_compression_cycle",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_huffman",
        "description": "SecureEncoderFlask.tests.test_huffman",
        "peekOfCode": "def test_huffman_compression_cycle():\n    \"\"\"Test Huffman compression and decompression.\"\"\"\n    encoded_data = huffman_compress(\"he\")\n    assert encoded_data == \"eyJjb21wcmVzc2VkX2RhdGEiOiAiTVRBPSIsICJzZXJpYWxpemVkX3RyZWUiOiB7ImxlZnQiOiB7ImNoYXIiOiAiZSJ9LCAicmlnaHQiOiB7ImNoYXIiOiAiaCJ9fX0=\"\n    decoded_data = huffman_decompress(encoded_data)\n    assert decoded_data == \"he\"\n# Additional tests for edge cases\n@pytest.mark.parametrize(\"text\", [\"\", \"a\", TEST_TEXT, SPECIAL_TEST_TEXT])\ndef test_compression_with_varied_text(text):\n    \"\"\"Test compression algorithms with varied text inputs.\"\"\"",
        "detail": "SecureEncoderFlask.tests.test_huffman",
        "documentation": {}
    },
    {
        "label": "test_compression_with_varied_text",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_huffman",
        "description": "SecureEncoderFlask.tests.test_huffman",
        "peekOfCode": "def test_compression_with_varied_text(text):\n    \"\"\"Test compression algorithms with varied text inputs.\"\"\"\n    functions = [\n        (huffman_compress, huffman_decompress),\n    ]\n    for compress, decompress in functions:\n        encoded = compress(text)\n        decoded = decompress(encoded)\n        assert decoded == text, f\"{compress.__name__} failed with text: {text}\"",
        "detail": "SecureEncoderFlask.tests.test_huffman",
        "documentation": {}
    },
    {
        "label": "TEST_TEXT",
        "kind": 5,
        "importPath": "SecureEncoderFlask.tests.test_huffman",
        "description": "SecureEncoderFlask.tests.test_huffman",
        "peekOfCode": "TEST_TEXT = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed non risus. Suspendisse lectus tortor, dignissim sit amet, adipiscing nec, ultricies sed, dolor. Cras elementum ultrices diam. Maecenas ligula massa, varius a, semper congue, euismod non, mi. Proin porttitor, orci nec nonummy molestie, enim est eleifend mi, non fermentum diam nisl sit amet erat. Duis semper. Duis arcu massa, scelerisque vitae, consequat in, pretium a, enim. Pellentesque congue. Ut in risus volutpat libero pharetra tempor. Cras vestibulum bibendum augue. Praesent egestas leo in pede. Praesent blandit odio eu enim. Pellentesque sed dui ut augue blandit sodales. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Aliquam nibh. Mauris ac mauris sed pede pellentesque fermentum. Maecenas adipiscing ante non diam sodales hendrerit.\"\nSPECIAL_TEST_TEXT = \"~!#$%^&*()_+\"\ndef test_huffman_compression_cycle():\n    \"\"\"Test Huffman compression and decompression.\"\"\"\n    encoded_data = huffman_compress(\"he\")\n    assert encoded_data == \"eyJjb21wcmVzc2VkX2RhdGEiOiAiTVRBPSIsICJzZXJpYWxpemVkX3RyZWUiOiB7ImxlZnQiOiB7ImNoYXIiOiAiZSJ9LCAicmlnaHQiOiB7ImNoYXIiOiAiaCJ9fX0=\"\n    decoded_data = huffman_decompress(encoded_data)\n    assert decoded_data == \"he\"\n# Additional tests for edge cases\n@pytest.mark.parametrize(\"text\", [\"\", \"a\", TEST_TEXT, SPECIAL_TEST_TEXT])",
        "detail": "SecureEncoderFlask.tests.test_huffman",
        "documentation": {}
    },
    {
        "label": "SPECIAL_TEST_TEXT",
        "kind": 5,
        "importPath": "SecureEncoderFlask.tests.test_huffman",
        "description": "SecureEncoderFlask.tests.test_huffman",
        "peekOfCode": "SPECIAL_TEST_TEXT = \"~!#$%^&*()_+\"\ndef test_huffman_compression_cycle():\n    \"\"\"Test Huffman compression and decompression.\"\"\"\n    encoded_data = huffman_compress(\"he\")\n    assert encoded_data == \"eyJjb21wcmVzc2VkX2RhdGEiOiAiTVRBPSIsICJzZXJpYWxpemVkX3RyZWUiOiB7ImxlZnQiOiB7ImNoYXIiOiAiZSJ9LCAicmlnaHQiOiB7ImNoYXIiOiAiaCJ9fX0=\"\n    decoded_data = huffman_decompress(encoded_data)\n    assert decoded_data == \"he\"\n# Additional tests for edge cases\n@pytest.mark.parametrize(\"text\", [\"\", \"a\", TEST_TEXT, SPECIAL_TEST_TEXT])\ndef test_compression_with_varied_text(text):",
        "detail": "SecureEncoderFlask.tests.test_huffman",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_md5_model",
        "description": "SecureEncoderFlask.tests.test_md5_model",
        "peekOfCode": "def app():\n    app = create_app({\n        'TESTING': True,\n        'SQLALCHEMY_DATABASE_URI': 'sqlite:///:memory:',\n        'WTF_CSRF_ENABLED': False  # Disable CSRF tokens in the form for testing purposes.\n    })\n    with app.app_context():\n        db.create_all()\n    return app\n@pytest.fixture",
        "detail": "SecureEncoderFlask.tests.test_md5_model",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_md5_model",
        "description": "SecureEncoderFlask.tests.test_md5_model",
        "peekOfCode": "def client(app):\n    return app.test_client()\ndef test_md5_encode(app):\n    # Use app context here for database operations\n    with app.app_context():\n        text = \"hello world\"\n        encoded = md5_encode(text)\n        stored_hash = MD5Hash.query.first()\n        assert stored_hash.md5_hash == encoded  # Ensure it's correctly stored in DB\n        assert len(encoded) == 32  # MD5 hashes should be 32 characters long",
        "detail": "SecureEncoderFlask.tests.test_md5_model",
        "documentation": {}
    },
    {
        "label": "test_md5_encode",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_md5_model",
        "description": "SecureEncoderFlask.tests.test_md5_model",
        "peekOfCode": "def test_md5_encode(app):\n    # Use app context here for database operations\n    with app.app_context():\n        text = \"hello world\"\n        encoded = md5_encode(text)\n        stored_hash = MD5Hash.query.first()\n        assert stored_hash.md5_hash == encoded  # Ensure it's correctly stored in DB\n        assert len(encoded) == 32  # MD5 hashes should be 32 characters long\ndef test_md5_decode(app):\n    with app.app_context():",
        "detail": "SecureEncoderFlask.tests.test_md5_model",
        "documentation": {}
    },
    {
        "label": "test_md5_decode",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_md5_model",
        "description": "SecureEncoderFlask.tests.test_md5_model",
        "peekOfCode": "def test_md5_decode(app):\n    with app.app_context():\n        text = \"hello world\"\n        encoded = md5_encode(text)\n        decoded = md5_decode(encoded)\n        assert decoded == text  # Ensure the decoded text matches the original\ndef test_md5_decode_no_match(app):\n    with app.app_context():\n        decoded = md5_decode(\"nonexistenthash\")\n        assert decoded == \"No match found\"  # Ensure correct message is returned when no match is found",
        "detail": "SecureEncoderFlask.tests.test_md5_model",
        "documentation": {}
    },
    {
        "label": "test_md5_decode_no_match",
        "kind": 2,
        "importPath": "SecureEncoderFlask.tests.test_md5_model",
        "description": "SecureEncoderFlask.tests.test_md5_model",
        "peekOfCode": "def test_md5_decode_no_match(app):\n    with app.app_context():\n        decoded = md5_decode(\"nonexistenthash\")\n        assert decoded == \"No match found\"  # Ensure correct message is returned when no match is found",
        "detail": "SecureEncoderFlask.tests.test_md5_model",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.flatted",
        "description": "SecureEncoderReact.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "SecureEncoderReact.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.flatted",
        "description": "SecureEncoderReact.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "SecureEncoderReact.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.flatted",
        "description": "SecureEncoderReact.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "SecureEncoderReact.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.flatted",
        "description": "SecureEncoderReact.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "SecureEncoderReact.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "def stringify(value):\n    return _stringify(value, separators=(',', ':'))\nassert stringify([None, None]) == '[[null,null]]'\na = []\no = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "a = []\no = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "o = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['o']",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "o['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)\na.append('two')\na.append(True)\no['one'] = 1\no['two'] = 'two'",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "b",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "b = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)\na.append('two')\na.append(True)\no['one'] = 1\no['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['one']",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "o['one'] = 1\no['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['two']",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "o['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['three']",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "o['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])\no['test'] = {'test': 'OK'}",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['a']",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "o['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])\no['test'] = {'test': 'OK'}\no['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['test']",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "o['test'] = {'test': 'OK'}\no['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['array']",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "o['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "a2",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "a2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o2",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "o2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "str",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "str = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "oo",
        "kind": 5,
        "importPath": "SecureEncoderReact.node_modules.flatted.python.test",
        "description": "SecureEncoderReact.node_modules.flatted.python.test",
        "peekOfCode": "oo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "SecureEncoderReact.node_modules.flatted.python.test",
        "documentation": {}
    }
]